# lightgbm-tutorial

学习 LightGBM 的产物。主要研究二分类问题，使用的数据集是 [adult](https://archive.ics.uci.edu/dataset/2/adult)

> **Note**: `requirements.txt` 中列出了部分依赖库的版本。考虑到 numpy 和 pandas 这样的通用库，版本升级时更注重向后兼容，一般不会因版本升级导致运行错误，故不予列明。
> 
> 如果你在运行过程中发生了错误，可以尝试执行以下命令，使用固定的包版本：
> 
> ```
> pip install -r requirements.txt
> ```

## 一、数据可视化

1. 导入数据
2. 统计描述
    - `describe()` 方法
    - `info()` 方法
    - 统计各字段枚举值数量
    - 查看字段下所有枚举值
    - 查看空值个数
3. 可视化
    - 标号的值的比例
    - 小提琴图 (Violin Plot)

## 二、预处理与特征选择

1. 预处理
    - 标签编码
    - 更好的编码方式？
2. 初次训练
    - 使用 `lgb.LGBMClassifier` 进行训练
    - 使用原生 API 进行训练
3. 简单评估
4. 模型存储与导入
    - 模型存储
    - 模型导入
5. 特征选择
    - 计算特征的重要程度
    - 多次实验求均值

## 三、超参数微调

1. 简单的例子
2. 稍微复杂的例子：随机森林
    - 导入数据
    - one-hot 编码
    - 训练
    - 评估
    - 超参数微调
    - 使用微调后的超参数训练
3. LightGMB 超参数微调
    - 单次训练
    - 超参数寻优
    - 使用微调后的超参数训练
4. 学习率衰减
    - 指数衰减
    - 自适应衰减

## 四、训练与评估

1. 基础模型
2. N 折交叉验证
3. 超参寻优：N 折交叉验证
4. 使用微调后的超参数训练
5. 阈值选择 (`y_pred -> y`)
    - 使用 `np.rint`
    - 尝试：考虑原标号的分布
        - 训练标号的分布情况
        - 预测标号的概率密度函数 (PDF)
        - 预测标号的概率分布函数 (CDF)
        - 当 CDF = `训练数据 0 标号比例` 时反推阈值
    - 使用 optuna 寻优
6. 评估
    - 混淆矩阵
    - 准确率
    - 精确率和召回率
    - `f1` 值
    - `log_loss` 交叉熵损失
    - ROC 曲线 与 AUC
    - 一站式评估函数

## 五、加速推理

1. 导入模型和数据
2. 使用 Treelite 加速推理
    - 推理速度
    - 推理准度
    - 通用函数

## 六、部署

1. 模型训练
2. 模型部署
    - 离线部署
    - 在线部署

## 七、模型可视化

1. 创建可交互的可视化界面
2. 将决策树存成 PNG / PDF
